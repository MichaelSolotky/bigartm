6. Tokens Co-occurrence and Coherence Computation
=================================================

* **Interpretability and Coherence of Topics**

The one of main requirements of topic models is interpretability (i.e., do the topics contain tokens that, according to subjective human judgment, are representative of single coherent concept). `Newman at al. <http://www.aclweb.org/anthology/N10-1012>`_ showed the human evaluation of interpretability is well correlated with the following automated quality measure called coherence. The coherence formula for topic is defined as

:math:`\mathcal{C}_t = \cfrac{2}{k(k - 1)} \sum\limits_{i = 1}^{k - 1} \sum\limits_{j = i}^{k} \mathrm{value}(w_i, w_j)`,

where value is some symetric pairwise information about tokens in collection dictionary, which is provided by user according to his goals. For instance, value can be computed by any corpora of texts by formulas:

* positive PMI: :math:`value(u,v)=\left[\log\cfrac{n(u,v)n}{n(u)n(v)}\right]_{+}`, 
* smoothed logarithm of conditional probability: :math:`value(u,v)=\log\cfrac{n(u,v)+1}{n(v)}`,

where `n(u)` and `n(v)` are frequencies of `u` and `v` in corpora, `n(u,v)` is joint frequency of `u` and `v` in corpora in window with some fixed width, `n` is length of corpora in words.

* **Tokens Co-occurrence Dictionary**

BigARTM provides automatic gathering of co-occurrence statistics and coherence computation. Co-occurrence gathering tool is available from :doc:`../bigartm_cli`. Here are types of co-occurrences available now:

* Cooc TF: :math:`n_{uv} = \sum\limits_{d = 1}^{|D|} \sum\limits_{i = 1}^{N_d} \sum\limits_{j = 1}^{N_d} [0 < |i - j| \leq k] [w_{di} = u] [w_{dj} = v]`,

* Cooc DF: :math:`n_{uv} = \sum\limits_{d = 1}^{|D|} [\, \exists \, i, j : w_{di} = u, w_{dj} = v, 0 < |i - j| \leq k]`, 

where k is parameter of window width which can be specified by user, D is collection, :math:`N_{d}` is length of document d. In brief cooc TF measures how many times the given pair occurred in the collection in a window and cooc DF measures in how many documents the given pair occurred at least once in a window of a given width.

* **Coherence Computation**

Let's assume you have file `cooc.txt` with co-occurrences of tokens. Also you should have vocabulary file in UCI format `vocab.txt` corresponding to `cooc.txt` file. Details about UCI format can be found here: :doc:`../datasets`.

To upload co-occurrence data into BigARTM you should use ``artm.Dictionary`` object and method ``gather``: ::

	cooc_dict = artm.Dictionary()
	cooc_dict.gather(
	    data_path='batches_folder',
	    cooc_file_path='cooc.txt',
	    vocab_file_path='vocab.txt',
	    symmetric_cooc_values=True)

Where 

* ``data_path`` is path to folder with your collection in internal BigARTM format (batches);
* ``cooc_file_path`` is path to file with co-occurrences of tokens;
* ``vocab_file_path`` is path to vocabulary file corresponding to `cooc.txt`;
* ``symmetric_cooc_values`` is Boolean argument. ``False`` means that co-occurrence information is not symmetric by order of tokens, i.e. `value(w1, w2)` and `value(w2, w1)` can be different.


So, now you can create coherence computation score: ::

	coherence_score = artm.TopTokensScore(
	                            name='TopTokensCoherenceScore',
	                            class_id='@default_class', 
	                            num_tokens=10, 
	                            topic_names=[u'topic_0',u'topic_1'],
	                            dictionary=cooc_dict)

Arguments:

* ``name`` is name of score;
* ``class_id`` is name of modality, which contains tokens with co-occurrence information;
* ``num_tokens`` is number ``k`` of used top tokens for topic coherence computation;
* ``topic_names`` is list of topic names for coherence computation;
* ``dictionary`` is artm.Dictionary with co-occurrence statistic.

To add ``coherence_score`` to the model use next line: ::

	model_artm.scores.add(coherence_score)

To access to results of coherence computation use, for example: ::

	model.score_tracker['TopTokensCoherenceScore'].average_coherence

General explanations and details about scores usage can be found here: :doc:`regularizers_and_scores`.
